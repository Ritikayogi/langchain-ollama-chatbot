# ğŸ¤– LangChain + Ollama (LLaMA2) GenAI Application

A **local Generative AI application** built using **LangChain**, **Ollama (LLaMA2)**, **FastAPI**, and **Streamlit**.  
This project generates **essays and poems** using a locally running LLM â€” **no OpenAI, no paid APIs**.

---

## ğŸŒŸ Key Features

- ğŸ§  **LLaMA2 via Ollama** (100% local & free)
- âš¡ **FastAPI backend** with LangServe
- ğŸ¨ **Streamlit frontend** for user interaction
- âœï¸ Generates:
  - Essays
  - Child-friendly poems
- ğŸ” Secure Git setup (no secrets pushed)
- ğŸ’» Runs completely on local machine

---

## ğŸ› ï¸ Tech Stack

- Python  
- LangChain  
- LangServe  
- Ollama (LLaMA2)  
- FastAPI  
- Streamlit  
- Uvicorn  
- Git & GitHub  

---

## ğŸ“ Project Structure

LANGCHAIN/
â”‚
â”œâ”€â”€ api/
â”‚ â””â”€â”€ app.py # FastAPI backend (LangChain + Ollama)
â”‚
â”œâ”€â”€ client.py # Streamlit frontend
â”œâ”€â”€ .gitignore # Ignored files (venv, .env, cache)
â”œâ”€â”€ README.md
â””â”€â”€ venv/ # Virtual environment (ignored)


---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Ritikayogi/langchain-ollama-chatbot.git
cd langchain-ollama-chatbot
```
###2ï¸âƒ£ Create & Activate Virtual Environment (Windows)
python -m venv venv
venv\Scripts\activate
3ï¸âƒ£ Install Dependencies
pip install langchain==0.1.16 langserve==0.0.51 langchain-community fastapi uvicorn streamlit requests
4ï¸âƒ£ Install Ollama & LLaMA2

Download Ollama from:
https://ollama.com

Pull the model:
ollama pull llama2
â–¶ï¸ Running the Application
ğŸ”¹ Start Backend (FastAPI)
cd api
python app.py
API: http://localhost:8000

Swagger Docs: http://localhost:8000/docs

ğŸ”¹ Start Frontend (Streamlit)

Open a new terminal (venv activated):

streamlit run client.py


App URL: http://localhost:8501
